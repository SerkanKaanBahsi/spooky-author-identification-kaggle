{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doğal Dil İşleme Proje.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0nkjbhyAYWr"
      },
      "source": [
        "## **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRz5-sckjw1-"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from keras import layers\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QFCzY8wKAcv"
      },
      "source": [
        "## Import Data From Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmGK3M8UXLk8"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnQq3RvrXJCe"
      },
      "source": [
        "! mkdir ~/.kaggle\r\n",
        "! cp kaggle.json ~/.kaggle/\r\n",
        "! chmod 600 ~/.kaggle/kaggle.json\r\n",
        "! kaggle competitions download -c spooky-author-identification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHgrVG6YBLFb"
      },
      "source": [
        "## **Constant Variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxXjiMxykCf5"
      },
      "source": [
        "MAXLEN = 192\r\n",
        "TEXTCOL = \"text\"\r\n",
        "TARGETCOL = \"author\"\r\n",
        "\r\n",
        "train_dir = \"train.zip\"\r\n",
        "test_dir = \"test.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBgYyshfBYr-"
      },
      "source": [
        "## **Get Train and Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rFNwW4-AypA"
      },
      "source": [
        "def get_data(train_dict, test_dict):\r\n",
        "  train = pd.read_csv(train_dict)\r\n",
        "  test = pd.read_csv(test_dict)\r\n",
        "  testdex = test.id\r\n",
        "\r\n",
        "  return train, test, testdex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kO3nRI0u34R"
      },
      "source": [
        "train, test, testdex = get_data(train_dir, test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtanOzmrMymE"
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfcqNXEaBr3Q"
      },
      "source": [
        "## Prepare Text Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMPwTc1hyR9R"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLkbY64KBuWF"
      },
      "source": [
        "def tokenize_data(train, test, TEXTCOL):\r\n",
        "  tokenizer = Tokenizer(num_words=26000)\r\n",
        "  tokenizer.fit_on_texts(train[TEXTCOL])\r\n",
        "\r\n",
        "  X_train = tokenizer.texts_to_sequences(train[TEXTCOL]) \r\n",
        "  X_test = tokenizer.texts_to_sequences(test[TEXTCOL])\r\n",
        "\r\n",
        "  vocab_size = len(tokenizer.word_index) + 1\r\n",
        "\r\n",
        "  X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, \r\n",
        "                                                          padding='post', \r\n",
        "                                                          maxlen=MAXLEN)\r\n",
        "  \r\n",
        "  X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, \r\n",
        "                                                         padding='post', \r\n",
        "                                                         maxlen=MAXLEN)\r\n",
        "\r\n",
        "  return X_train, X_test, vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPF131NUGmxr"
      },
      "source": [
        "X_train, X_test, vocab_size = tokenize_data(train, test, TEXTCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arFyTA1FyUnQ"
      },
      "source": [
        "### Prepare Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BDDcFjECodS"
      },
      "source": [
        "def get_labels(TARGETCOL, train):\r\n",
        "  label_mapper = {name: i for i,name in enumerate(set(train[TARGETCOL].values))}\r\n",
        "  num_label = np.vectorize(label_mapper.get)(train[TARGETCOL].values)\r\n",
        "  train_labels = to_categorical(num_label)\r\n",
        "  \r\n",
        "  return train_labels, label_mapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0BnH7NJGxgX"
      },
      "source": [
        "train_labels, label_mapper = get_labels(TARGETCOL, train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBBNKmavJe37"
      },
      "source": [
        "label_mapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqs0iSswJ0z3"
      },
      "source": [
        "### Submission Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbrMrh8eJNzF"
      },
      "source": [
        "def prepare_submission(testdex, test_results, label_mapper, model_name):\r\n",
        "  testdex = test.id\r\n",
        "  submission = pd.read_csv(\"sample_submission.zip\")\r\n",
        "  sub_cols = submission.columns\r\n",
        "\r\n",
        "  submission = pd.DataFrame(test_result, columns=label_mapper.keys())\r\n",
        "  submission['id'] = testdex\r\n",
        "\r\n",
        "  submission = submission[sub_cols]\r\n",
        "  submission.to_csv(model_name + '_results.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fTt8pZEv4OJ"
      },
      "source": [
        "## Model With Embedding and Dense Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPqvE8-_D5C9"
      },
      "source": [
        "def build_model(vocab_size):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(layers.Embedding(input_dim=vocab_size, \r\n",
        "                             output_dim=500, \r\n",
        "                             input_length=MAXLEN))\r\n",
        "\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(1024, activation='relu'))\r\n",
        "  model.add(layers.Dropout(0.2))\r\n",
        "  model.add(layers.Dense(3, activation='softmax'))\r\n",
        "\r\n",
        "  model.compile(optimizer='adam', \r\n",
        "                loss='categorical_crossentropy', \r\n",
        "                metrics=['accuracy'])\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv7JetDn4Wxw"
      },
      "source": [
        "model = build_model(vocab_size)\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0qJzS5kEtLY"
      },
      "source": [
        "history = model.fit(X_train, train_labels,\r\n",
        "                    epochs=5,\r\n",
        "                    validation_split=0.2,\r\n",
        "                    batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q9JPNiDEURZ"
      },
      "source": [
        "model_test_result = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4diR1Qupt80v"
      },
      "source": [
        "prepare_submission(testdex, _model_test_result, label_mapper, \"basic_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0MwcsLhxOY1"
      },
      "source": [
        "## GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ0yYwSMxQyd"
      },
      "source": [
        "def build_GRU(vocab_size):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(layers.Embedding(input_dim=vocab_size, \r\n",
        "                           output_dim=500, \r\n",
        "                           input_length=MAXLEN))\r\n",
        "  \r\n",
        "  model.add(layers.GRU(128, return_sequences=True, activation=\"tanh\"))\r\n",
        "  model.add(layers.GRU(256, return_sequences=True, activation=\"tanh\"))\r\n",
        "\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(1024, activation='relu'))\r\n",
        "  model.add(layers.Dropout(0.2))\r\n",
        "  model.add(layers.Dense(3, activation='softmax'))\r\n",
        "\r\n",
        "  model.compile(optimizer='adam', \r\n",
        "                loss='categorical_crossentropy', \r\n",
        "                metrics=['accuracy'])\r\n",
        "  \r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABsRsAx5xXhZ"
      },
      "source": [
        "gru_model = build_GRU(vocab_size)\r\n",
        "gru_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks5hRsKpyBIe"
      },
      "source": [
        "history = gru_model.fit(X_train, train_labels,\r\n",
        "                    epochs=5,\r\n",
        "                    validation_split=0.2,\r\n",
        "                    batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ElK6_Hx9rWo"
      },
      "source": [
        "gru_test_result = gru_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxaQef99uG_F"
      },
      "source": [
        "prepare_submission(testdex, gru_test_results, label_mapper, \"gru\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AwwnhGMwAIe"
      },
      "source": [
        "## LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz26sNO1Flhb"
      },
      "source": [
        "def build_LSTM(vocab_size):\r\n",
        "  model = Sequential()\r\n",
        "\r\n",
        "  model.add(layers.Embedding(input_dim=vocab_size,\r\n",
        "                             output_dim=500,\r\n",
        "                             input_length=MAXLEN))\r\n",
        "\r\n",
        "  model.add(layers.LSTM(128,return_sequences=True))\r\n",
        "  model.add(layers.LSTM(256,return_sequences=True))\r\n",
        "  \r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(1024, activation=\"relu\"))\r\n",
        "  model.add(layers.Dropout(0.2))\r\n",
        "  model.add(layers.Dense(3, activation='softmax'))\r\n",
        "\r\n",
        "  model.compile(loss='categorical_crossentropy',\r\n",
        "                optimizer='adam', \r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGaq7z10G9rZ"
      },
      "source": [
        "lstm_model = build_LSTM(vocab_size)\r\n",
        "lstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RNB3EB6895p"
      },
      "source": [
        "history = lstm_model.fit(X_train, \r\n",
        "                         train_labels, \r\n",
        "                         epochs=5, \r\n",
        "                         validation_split=0.2, \r\n",
        "                         batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL5yzsAG9yhN"
      },
      "source": [
        "lstm_test_result = lstm_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz5VgUyquLdp"
      },
      "source": [
        "prepare_submission(testdex, lstm_test_results, label_mapper, \"lstm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOx1BcwJwDtT"
      },
      "source": [
        "## Simple RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqfspO8rHEmA"
      },
      "source": [
        "def build_simple_RNN(vocab_size):\r\n",
        "  model = Sequential()\r\n",
        "\r\n",
        "  model.add(layers.Embedding(input_dim=vocab_size, \r\n",
        "                             output_dim=500, \r\n",
        "                             input_length=MAXLEN))\r\n",
        "\r\n",
        "  model.add(layers.SimpleRNN(128, dropout=0.2,return_sequences=True))\r\n",
        "  model.add(layers.SimpleRNN(256, dropout=0.2,return_sequences=True))\r\n",
        "  \r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(1024, activation=\"relu\"))\r\n",
        "  model.add(layers.Dropout(0.2))\r\n",
        "  model.add(layers.Dense(3, activation='softmax'))\r\n",
        "\r\n",
        "  model.compile(loss='categorical_crossentropy', \r\n",
        "                optimizer='adam', \r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mfskyjOHKeN"
      },
      "source": [
        "rnn_model = build_simple_RNN(vocab_size)\r\n",
        "rnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF5m8BrI-9Yr"
      },
      "source": [
        "history = rnn_model.fit(X_train, \r\n",
        "                        train_labels, \r\n",
        "                        epochs=5, \r\n",
        "                        validation_split=0.2, \r\n",
        "                        batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkJHTDdP93hF"
      },
      "source": [
        "rnn_test_result = rnn_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KmoKMNguO93"
      },
      "source": [
        "prepare_submission(testdex, rnn_test_results, label_mapper, \"rnn\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}